{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stress Testing Common XAI Algos in the Literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cmore\\AppData\\Local\\Temp\\ipykernel_20188\\3432327004.py:15: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lime\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from classifiers.ClassifierWrapper import ClassifierWrapper\n",
    "from classifiers.XGBoost import XGBoost\n",
    "from classifiers.BNetClassifier import BayesNet\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "%matplotlib inline\n",
    "\n",
    "import pyAgrum as gum\n",
    "import pyAgrum.lib.notebook as gnb\n",
    "\n",
    "\n",
    "SMALL_SIZE = 10\n",
    "MEDIUM_SIZE = 12\n",
    "plt.rc('font', size=SMALL_SIZE)\n",
    "plt.rc('axes', titlesize=MEDIUM_SIZE)\n",
    "plt.rc('axes', labelsize=MEDIUM_SIZE)\n",
    "plt.rcParams['figure.dpi']=150\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case #1: Data Generated from a Common Cause Structure with Independent Vars\n",
    "\n",
    "The purpose of this test is to understand how current algorithms of the literature such as LIME and SHAP can represent feature in important in situations where data is generated from a common cause structure. We also added an independent variable to understand if this variable will be considered as relevant to the algorithm. We will train an XGboost classifier with data generated from the model below and run XAI algortihms to understand the computed feature importance.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/catarina-moreira/XAI_Algos/0de91f13187c7a136676e049804c6b6e4de3ff44/networks/common_cause.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.162166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.724821</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.784591</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.216756</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.828123</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1  X2  Y\n",
       "0  0.162166   0  0\n",
       "1  0.724821   1  0\n",
       "2  0.784591   1  1\n",
       "3  0.216756   0  0\n",
       "4  0.828123   0  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the common cause data\n",
    "data_common_cause = pd.read_csv(os.path.join(\"gen_data\", \"common_cause_v3.dat\"))\n",
    "data_common_cause.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cmore\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1036: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=14.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "clf_BNet = BayesNet(False, \"common_cause_v3\", data_common_cause,\"Y\")\n",
    "clf_BNet.classify(save_model=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_xgboost = XGBoost(False, \"common_cause_v3\", data_common_cause,\"Y\")\n",
    "clf_xgboost.classify()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_bn = Classifier(\"Bayesian Network\", \"common_cause_v2\", data_common_cause, \"Y\")\n",
    "bnc = clf_bn.applyClassifer(learningMethod=\"GHC\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.showBN(bnc.bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb.showInference(bnc.bn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_nn = Classifier(\"Neural Network\", \"common_cause_v2\", data_common_cause, \"Y\")\n",
    "NN = clf_nn.applyClassifer()\n",
    "NN\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Neural Network Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs = pd.DataFrame(history.history)\n",
    "\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(logs.loc[5:,\"loss\"], lw=2, label='training loss')\n",
    "plt.plot(logs.loc[5:,\"val_loss\"], lw=2, label='validation loss')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(logs.loc[5:,\"accuracy\"], lw=2, label='training accuracy score')\n",
    "plt.plot(logs.loc[5:,\"val_accuracy\"], lw=2, label='validation accuracy score')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training an XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Explanations for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  lime.lime_tabular import LimeTabularExplainer\n",
    "explainer = LimeTabularExplainer(X_train, feature_names=features, class_names=[\"Y:0\", \"Y:1\"])\n",
    "explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 5\n",
    "\n",
    "res = xgb.predict_proba([X_test[indx]])\n",
    "print( \"Prediction: \" + str(np.argmax(res[0])) )\n",
    "\n",
    "exp = explainer.explain_instance(X_test[indx], xgb.predict_proba, num_features=3)\n",
    "fig = exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Explanations for Neural Net\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  lime.lime_tabular import LimeTabularExplainer\n",
    "explainer_nn = LimeTabularExplainer(X_train, feature_names=features, class_names=[\"Y:0\", \"Y:1\"])\n",
    "explainer_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_fn = lambda x:  1.0 if nn.predict(x) >= 0.5 else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indx = 5\n",
    "\n",
    "instance1 =  np.expand_dims(X_test[indx], axis=0) \n",
    "instance2 =  X_test[indx]\n",
    "\n",
    "exp = explainer.explain_instance(X_test[indx], nn.predict, num_features=3)\n",
    "fig = exp.as_pyplot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_bn = LimeTabularExplainer(X_train, feature_names=features, class_names=[\"Y:0\", \"Y:1\"])\n",
    "explainer_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6260509064eb67b36916815bc82da85b0a66bf2dbc63b7ed396e364365f7498b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
